Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

Jonas Mueller 1 David Gifford 1 Tommi Jaakkola 1

Abstract

We present a model that, after learning on ob-
servations of (sequence, outcome) pairs, can be
efﬁciently used to revise a new sequence in order
to improve its associated outcome. Our frame-
work requires neither example improvements,
nor additional evaluation of outcomes for pro-
posed revisions. To avoid combinatorial-search
over sequence elements, we specify a generative
model with continuous latent factors, which is
learned via joint approximate inference using a
recurrent variational autoencoder (VAE) and an
outcome-predicting neural network module. Un-
der this model, gradient methods can be used to
efﬁciently optimize the continuous latent factors
with respect to inferred outcomes. By appropri-
ately constraining this optimization and using the
VAE decoder to generate a revised sequence, we
ensure the revision is fundamentally similar to
the original sequence, is associated with better
outcomes, and looks natural. These desiderata
are proven to hold with high probability under
our approach, which is empirically demonstrated
for revising natural language sentences.

those which appear realistic). For example: a random se-
quence of words will almost never form a coherent sentence
that reads naturally, and a random amino-acid sequence is
highly unlikely to specify a biologically active protein.
In this work, we consider applications where each sequence
x is associated with a corresponding outcome y P R.
For example: a news article title or Twitter post can be
associated with the number of shares it subsequently re-
ceived online, or the amino-acid sequence of a synthetic
protein can be associated with its clinical efﬁcacy. We op-
erate under the standard supervised learning setting, assum-
iid„ pXY
ing availability of a dataset Dn “ tpxi, yiqun
i“1
of sequence-outcome pairs. The marginal distribution
pX is assumed as a generative model of the natural se-
quences, and may be concentrated in a small subspace of
X . Throughout this paper, p denotes both density and dis-
tribution functions depending on the referenced variable.
After ﬁtting models to Dn, we are presented a new se-
quence x0 P X (with unknown outcome), and our goal is to
quickly identify a revised version that is expected to have
superior outcome. Formally, we seek the revised sequence:
(1)

ErY | X “ xs

x˚ “ argmax
xPCx0

Introduction
The success of recurrent neural network (RNN) models
in complex tasks like machine translation and audio syn-
thesis has inspired immense interest in learning from se-
quence data (Eck & Schmidhuber, 2002; Graves, 2013;
Sutskever et al., 2014; Karpathy, 2015). Comprised of ele-
ments st P S, which are typically symbols from a discrete
vocabulary, a sequence x “ ps1, . . . , sTq P X has length T
which can vary between different instances. Sentences are
a popular example of such data, where each sj is a word
from the language. In many domains, only a tiny fraction
of X (the set of possible sequences over a given vocabu-
lary) represents sequences likely to be found in nature (ie.

1MIT Computer Science & Artiﬁcial Intelligence Laboratory.
Correspondence to: J. Mueller <jonasmueller@csail.mit.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Here, we want the set Cx0 of feasible revisions to ensure
that x˚ remains natural and is merely a minor revision of
x0. Under a generative modeling perspective, these two
goals are formalized as the following desiderata: pXpx˚q is
not too small, and x˚ and x0 share similar underlying latent
characteristics. When revising a sentence for example, it is
imperative that the revision reads naturally (has reasonable
likelihood under the distribution of realistic sentences) and
retains the semantics of the original.
This optimization is difﬁcult because the constraint-set and
objective may be highly complex and are both unknown
(must be learned from data). For many types of sequence
such as sentences, standard distance measures applied di-
rectly in the space of X or S (eg. Levenshtein distance or
TF-IDF similarity) are inadequate to capture meaningful
similarities, even though these can be faithfully reﬂected by
a simple metric over an appropriately learned space of con-
tinuous latent factors (Mueller & Thyagarajan, 2016). In
this work, we introduce a generative-modeling framework
which transforms (1) into a simpler differentiable optimiza-

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

tion by leveraging continuous-valued latent representations
learned using neural networks. After the generative model
has been ﬁt, our proposed procedure can efﬁciently revise
any new sequence in a manner that satisﬁes the aforemen-
tioned desiderata (with high probability).

Related Work
Unlike imitation learning, our setting does not require
availability of improved versions of a particular sequence.
This prevents direct application of a sequence-to-sequence
model (Sutskever et al., 2014). Similar to our approach,
G´omez-Bombarelli et al. (2016) also utilize latent autoen-
coder representations in order to propose novel chemical
structures via Bayesian optimization. However, unlike se-
quential bandit/reinforcement-learning settings, our learner
sees no outcomes outside of the training data, neither for
the new sequence it is asked to revise, nor for any of its
proposed revisions of said sequence (Mueller et al., 2017).
Our methods only require an easily-assembled dataset of
sequence-outcome pairs and are thus widely applicable.
Combinatorial structures are often optimized via complex
search heuristics such as genetic programming (Zaefferer
et al., 2014). However, search relies on evaluating iso-
lated changes in each iteration, whereas good revisions of
a sequence are often made over a larger context (ie. al-
tering a phrase in a sentence). From the vast number of
possibilities, such revisions are unlikely to be found by
search-procedures, and it is generally observed that such
methods are outperformed by gradient-based optimization
in high-dimensional continuous settings. Unlike combina-
torial search, our framework leverages gradients in order to
efﬁciently ﬁnd good revisions at test time. Simonyan et al.
(2014) and Nguyen et al. (2015) also proposed gradient-
based optimization of inputs with respect to neural predic-
tions, but work in this vein has been focused on conditional
generation (rather than revision) and is primarily restricted
to the continuous image domain (Nguyen et al., 2016).

Methods
To identify good revisions, we ﬁrst map our stochastic com-
binatorial optimization problem into a continuous space
where the objective and constraints exhibit a simpler form.
We assume the data are generated by the probabilistic
graphical model in Figure 1A. Here, latent factors Z P Rd
specify a (continuous) conﬁguration of the generative pro-
cess for X, Y (both sequences and outcomes), and we
adopt the prior pZ “ Np0, Iq. Relationships between these
variables are summarized by the maps F, E, D which we
parameterize using three neural networks F , E, D trained
to enable efﬁcient approximate inference under this model.
The ﬁrst step of our framework is to ﬁt this model to Dn

(A) Graphical Model

F

z

y

x

E

D

(B) Revision Procedure
y0

§ . . . §

§

y1

y˚

F

F
`rzF

z0

`rzF

. . .

z1

F
`rzF

z˚

E

x0

D

x˚

Figure 1. (A) Assumed graphical model (shaded nodes indicate
observed variables, dashed arrows are learned neural network
mappings). (B) Procedure for revising a given x0 to produce x˚
with superior expected outcome.

by learning the parameters of these inference networks: the
encoder E, the decoder D, and the outcome-predictor F .
A good model that facilitates high-quality revision under
our framework will possess the following properties: (1)
Y can efﬁciently be inferred from Z and this relationship
obeys a smooth functional form, (2) the map D produces
a realistic sequence x given any z with reasonable prior
probability, (3) the distribution of natural sequences is ge-
ometrically simple in the latent Z-space. We explicitly en-
courage (1) by choosing F as a fairly simple feedforward
network, (2) by deﬁning D as the most-likely x given z,
and (3) by endowing Z with our simple Np0, Iq prior.
Another characteristic desired of our Z-representations is
that they encode meaningful sequence-features such that
two fundamentally similar sequences are likely to have
been generated from neighboring z-values. Applied to im-
age data, VAE models similar to ours have been found to
learn latent representations that disentangle salient char-
acteristics such as scale, rotation, and other independent
visual concepts (Higgins et al., 2016). The latent repre-
sentations of recurrent architectures trained on text (similar
to the models used here) have also been shown to encode
meaningful semantics, with a strong correlation between
distances in the latent space and human-judged similarity
between texts (Mueller & Thyagarajan, 2016). By exploit-
ing such simpliﬁed geometry, a basic shift in the latent
vector space may be able to produce higher-quality revi-
sions than attempts to directly manipulate the combinato-
rial space of sequence elements.
After ﬁtting a model with these desirable qualities, our
strategy to revise a given sequence x0 P X is outlined
in Figure 1B. First, we compute its latent representation
z0 “ Epx0q using a trained encoding map. As the latent
representations z are continuous, we can employ efﬁcient
gradient-based optimization to ﬁnd a nearby local optimum
z˚ of Fpzq (within a simple constraint-set around z0 de-
ﬁned later on). To z˚, we subsequently apply a simple de-
coding map D (deﬁned with respect to our learned model)
in order to obtain our revised sequence x˚. Under our

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

assumed model, the optimization in latent representation-
space attempts to identify a generative conﬁguration which
produces large values of Y (as inferred via F ). The sub-
sequent decoding step seeks the most likely sequence pro-
duced by the optimized setting of the latent factors.

Variational Autoencoder
For approximate inference in the X, Z relationship, we
leverage the variational autoencoder (VAE) model of
Kingma & Welling (2014). In our VAE, a generative model
of sequences is speciﬁed by our prior over the latent values
z combined with a likelihood function pDpx | zq which our
decoder network D outputs in order to evaluate the likeli-
hood of any sequence x given z P Rd. Given any sequence
x, our encoder network E outputs a variational approxima-
tion qEpz | xq of the true posterior over the latent-values
ppz | xq9 pDpx | zqpZpzq. As advocated by Kingma &
Welling (2014) and Bowman et al. (2016), we employ the
variational family qEpz | xq “ Npµz|x, ⌃z|x) with diag-
onal covariance. Our revision methodology employs the
encoding procedure Epxq “ µz|x which maps a sequence
to the maximum a posteriori (MAP) conﬁguration of the
latent values z (as estimated by the encoder network E).
The parameters of E, D are learned using stochastic
variational inference to maximize a lower bound for the
marginal likelihood of each observation in the training data:

log pXpxq • ´“Lrecpxq ` Lpripxq‰
Lrecpxq “ ´EqEpz|xq rlog pDpx | zqs
Lpripxq “ KLpqEpz | xq|| pZq

(2)

Deﬁning  z|x “ diagp⌃z|xq, the prior-enforcing Kullback-
Leibler divergence has a differentiable closed form expres-
sion when qE, pZ are diagonal Gaussian distributions. The
reconstruction term Lrec (ie. negative log-likelihood under
the decoder model) is efﬁciently approximated using just
one Monte-Carlo sample z „ qEpz | xq. To optimize the
variational lower bound over our data Dn with respect to
the parameters of neural networks E, D, we use stochas-
tic gradients of (2) obtained via backpropagation and the
reparameterization trick of Kingma & Welling (2014).
Throughout, our encoder/decoder models E, D are recur-
rent neural networks (RNN). RNNs adapt standard feedfor-
ward neural networks for sequence data x “ ps1, . . . , sTq,
where at each time-step t P t1, . . . , Tu, a ﬁxed size hidden-
state vector ht P Rd is updated based on the next element
in the input sequence. To produce the approximate pos-
terior for a given x, our encoder network E appends the
following additional layers to the ﬁnal RNN hidden-state
(parameterized by Wµ, W , Wv, bµ, b , bv):
µz|x “ WµhT ` bµ P Rd
 z|x “ expp´|W v ` b |q, v “ ReLUpWvhT ` bvq (3)

The (squared) elements of  z|x P Rd form the diagonal of
our approximate-posterior covariance ⌃z|x. Since Lpri is
minimized at  z|x “ ~1 and Lrec is likely to worsen with
additional variance in encodings (as our posterior approx-
imation is unimodal), we simply do not consider  z|x val-
ues that exceed 1 in our variational family. This restriction
results in more stable training and also encourages the en-
coder and decoder to co-evolve such that the true posterior
is likely closer to unimodal with variance § 1.
To evaluate the likelihood of a sequence, RNN D computes
not only its hidden state ht, but also the additional output:

⇡t “ softmaxpW⇡ht ` b⇡q

(4)

At each position t, ⇡t estimates ppst | s1, . . . , st´1q by re-
lying on ht to summarize the sequence history. By the
factorization pps1, . . . , sTq “ ±T
t“1 ppst | st´1, . . . , s1q,
we have pDpx | zq “±T
t“1 ⇡trsts, which is calculated by
specifying an initial hidden-state h0 “ z and feeding
x “ ps1, . . . , sTq into D. From a given latent conﬁguration
z, our revisions are produced by decoding a sequence via
the most-likely observation, which we denote as the map:

Dpzq “ argmax
xPX

pDpx | zq

(5)

While the most-likely decoding in (5) is itself a combi-
natorial problem, beam search can exploit the sequential-
factorization of ppx | zq to efﬁciently ﬁnd a good approx-
imate solution (Wiseman & Rush, 2016; Sutskever et al.,
2014). For x˚ “ Dpzq P X , this decoding strategy seeks
to ensure neither pXpx˚q nor ppz | x˚q is too small.
Compositional Prediction of Outcomes
In addition to the VAE component, we ﬁt a composi-
tional outcome-prediction model which uses a standard
feed forward neural network F to implement the map
F : Rd Ñ R. It is assumed that Fpzq “ ErY | Z “ zs un-
der our generative model. Rather than integrating over Z
to compute ErY | X “ xs “≥ FpzqqEpz | xqdz, we em-
ploy the ﬁrst-order Taylor approximation FpEpxqq, where
the approximation-error shrinks the more closely F resem-
bles an afﬁne transformation. To ensure this approximate-
inference step accurately estimates the conditional expec-
tation, we jointly train E and F with the loss:

Lmsepx, yq “ ry ´ FpEpxqqs2

(6)

If the architecture of networks E, F is speciﬁed with suf-
ﬁcient capacity to capture the underlying conditional rela-
tionship, then we should have FpEpxqq « ErY | X “ xs
after properly learning the network parameters from a suf-
ﬁciently large dataset (even F is a nonlinear map).

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

Enforcing Invariance
In theory, it is possible that some dimensions of z pertain
solely to the outcome y and do not have any effect on the
decoded sequence Dpzq. Happening to learn this sort of
latent representation would be troubling, since subsequent
optimization of the inferred y with respect to z might not
actually lead to a superior revised sequence. To mitigate
this issue, we carefully ensure the dimensionality d of our
latent Z does not signiﬁcantly exceed the bottleneck ca-
pacity needed to produce accurate outcome-predictions and
VAE reconstructions (Gupta et al., 2016). We explicitly
suppress this undesirable scenario by adding the following
loss to guide training of our neural networks:

(7)

Linv “ Ez„pZ“Fpzq ´ FpEpDpzqqq‰2

When optimizing neural network parameters with respect
to this loss, we treat the parameters of D and the lefthand
Fpzq term as ﬁxed, solely backpropagating Monte-Carlo
estimated gradients into E, F . Driving Linv toward 0 en-
sures our outcome-predictions remain invariant to varia-
tion introduced by the encoding-decoding process (and this
term also serves as a practical regularizer to enforce addi-
tional smoothness in our learned functions).

Joint Training
The parameters of all components of this model (qE, pD,
and F ) are learned jointly in an end-to-end fashion. Train-
ing is done via stochastic gradient descent applied to mini-
mize the following objective over the examples in Dn:
Y Linv
 2

Lpx, yq “ Lrec `  priLpri `  mse

Y Lmse `  inv

(8)

 2

where  2
Y denotes the (empirical) variance of the outcomes,
and the   • 0 are constants chosen to balance the relative
weight of each goal so that the overall framework produces
maximally useful revisions. By setting  mse “  inv “ 0
at ﬁrst, we can optionally leverage a separate large cor-
pus of unlabeled examples to initially train only the VAE
component of our architecture, as in the unsupervised pre-
training strategy used successfully by Kiros et al. (2015);
Erhan et al. (2010).
In practice, we found the following training strategy to
work well, in which numerous mini-batch stochastic gra-
dient updates (typically 10-30 epochs) are applied within
every one of these steps:
Step 1: Begin with  inv “  pri “ 0, so Lrec and Lmse
are the only training objectives. We found that regardless
of the precise value speciﬁed for  mse, both Lrec and Lmse
were often driven to their lowest possible values during this
joint optimization (veriﬁed by training individually against
each objective).

Step 2: Grow  pri from 0 to 1 following the sigmoid an-
nealing schedule proposed by Bowman et al. (2016), which
is needed to ensure the variational sequence to sequence
model does not simply ignore the encodings z (note that
the formal variational lower bound is attained at  pri “ 1).
Step 3: Gradually increase  inv linearly until Linv becomes
small on average across our Monte-Carlo samples z „ pZ.
Here, pD is treated as constant with respect to Linv, and
each mini-batch used in stochastic gradient descent is cho-
sen to contain the same number of Monte-Carlo samples
for estimating Linv as (sequence, outcome) pairs.
Proposing Revisions
While the aforementioned training procedure is computa-
tionally intensive, once learned, our neural networks can
be leveraged for efﬁcient inference. Given user-speciﬁed
constant ↵ ° 0 and a to-be-revised sequence x0, we pro-
pose the revision x˚ output by the following procedure.

Fpzq

(beam search)

(gradient ascent)

REVISE Algorithm
Input: sequence x0 P X , constant ↵ P p0,|2⇡⌃z|x0|´ 1
2q
Output: revised sequence x˚ P X
1) Use E to compute qEpz | x0q
2) Deﬁne Cx0 “ z P Rd : qEpz | x0q • ↵(
3) Find z˚ “ argmax
zPCx0
4) Return x˚ “ Dpz˚q
Intuitively, the level-set constraint Cx0 Ñ Rd ensures that
z˚, the latent conﬁguration from which we decode x˚, is
likely similar to the latent characteristics responsible for the
generation of x0. Assuming x0 and x˚ share similar latent
factors implies these sequences are fundamentally similar
according to the generative model. Note that z˚ “ Epx0q
is always a feasible solution of the latent-factor optimiza-
tion over z P Cx0 (for any allowed value of ↵). Further-
more, this constrained optimization is easy under our Gaus-
sian approximate-posterior, since Cx0 forms a simple ellip-
soid centered around Epx0q.
To ﬁnd z˚ in Step 3 of the REVISE procedure, we use gra-
dient ascent initialized at z “ Epx0q, which can quickly
reach a local maximum if F is parameterized by a simple
feedforward network. Starting the search at Epx0q makes
most sense for unimodal posterior approximations like our
Gaussian qE. To ensure all iterates remain in the feasible
region Cx0, we instead take gradient steps with respect to a
penalized objective Fpzq ` µ ¨ Jpzq where:
z|x0pz ´ Epx0qqı
Jpzq “ log”K ´ pz ´ Epx0qqT ⌃´1
K “ ´2 logrp2⇡qd{2|⌃z|x|1{2↵s
(9)
and 0 † µ ! 1 is gradually decreased toward 0 to en-

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

sure the optimization can approach the boundary of Cx0. In
terms of resulting revision quality, we found this log barrier
method outperformed other standard ﬁrst-order techniques
for constrained optimization such as the projected gradient
and Franke-Wolfe algorithms.
In principle, our revision method can operate on the latent
representations of a traditional deterministic autoencoder
for sequences, such as the seq2seq models of Sutskever
et al. (2014) and Cho et al. (2014). However, the VAE
offers numerous practical advantages, some of which are
highlighted by Bowman et al. (2016) in the context of gen-
erating more-coherent sentences. The posterior uncertainty
of the VAE encourages the network to smoothly spread the
training examples across the support of the latent distribu-
tion. In contrast, central regions of the latent space under a
traditional autoencoder can contain holes (to which no ex-
amples are mapped), and it is not straightforward to avoid
these in our optimization of z˚. Furthermore, we introduce
an adaptive variant of our decoder in §S1 which is designed
to avoid poor revisions in cases where the initial sequence
is already not reconstructed properly: DpEpx0qq ‰ x0.
Theoretical Properties of Revision
Here, we theoretically characterize properties of revisions
obtained via our REVISE procedure (all proofs are rel-
egated to §S3 in the Supplementary Material). Our re-
sults imply that in an ideal setting where our neural net-
work inference approximations are exact, the revisions pro-
posed by our method are guaranteed to satisfy our previ-
ously stated desiderata: x˚ is associated with an expected
outcome-increase, x˚ appears natural (has nontrivial prob-
ability under pX whenever x0 is a natural sequence), and
x˚ is likely to share similar latent characteristics as x0
(since x˚ is the most likely observation generated from
z˚ and qEpz˚ | x0q • ↵ by design). Although exact
approximations are unrealistic in practice, our theory pre-
cisely quantiﬁes the expected degradation in the quality of
proposed revisions that accompanies a decline in either the
accuracy of our approximate inference techniques or the
marginal likelihood of the original sequence to revise.
Theorems 1 and 2 below ensure that for an initial sequence
x0 drawn from the natural distribution, the likelihood of the
revised sequence x˚ output by our REVISE procedure un-
der pX has lower bound determined by the user-parameter
↵ and the probability of the original sequence pXpx0q.
Thus, when revising a sequence x0 which looks natural
(has substantial probability under pX), our procedure is
highly likely to produce a revised sequence x˚ which also
looks natural. The strength of this guarantee can be pre-
cisely controlled by choosing ↵ appropriately large in ap-
plications where this property is critical.
In each high probability statement, our bounds assume the

distribution deﬁned by Hoffman & Johnson (2016) as:

ppz | xq •   ¨ qEpz | xq whenever qEpz | xq • ↵

initial to-be-revised sequence x0 stems from the natural
distribution pX, and each result holds for any ﬁxed con-
stant   ° 0. We ﬁrst introduce the following assumptions:
(A1) For   ° 0, ↵ ° 0, there exists 0 †   § 1 such that:
i. With probability • 1 ´  {2 (over x „ pX):
ii. PrpZ R BR{2p0qq •   ¨ PrprZ R BR{2p0qq
where Z „ Np0, Iq, and rZ „ qZ, the average encoding
(10)
qZpzq “ Ex„pXrqEpz | xqs
BRp0q “ tz P Rd : ||z|| § Ru denotes the Euclidean ball
centered around 0 with radius R deﬁned here as:
(11)
R “ maxtR1, R2u
with R1 “a´8 logr↵ ¨ p2⇡qd{2s
R2 “ maxtrR2, 2u, rR2 “c8 ´ 1
4d log´   
8¯
(A2) There exists ⌘ ° 0 (depends on  ) such that with
ppz˚ | x˚q § ⌘
probability • 1 ´  {2 (over x0 „ pX):
This means the latent posterior is bounded at x˚, z˚ (as
deﬁned in REVISE), where both depend upon the initial to-
be-revised sequence x0.
Theorem 1. For any   ° 0, (A1) and (A2) imply:

pXpx˚q • ↵ 

⌘ ¨ pXpx0q
with probability • 1 ´   (over x0 „ pX).
Condition (A1) forms a generalization of absolute conti-
nuity, and is required since little can be guaranteed about
our inference procedures if the variational posterior is too
inaccurate. Equality holds in (A1) with probability 1 if the
variational distributions qE exactly represent the true poste-
rior (  Ñ 1 as the variational approximations become more
accurate over the measure pX). In practice, minimization
of the reverse KL divergence (Lpri) used in our VAE for-
mulation ensures that qEpz | xq is small wherever the true
posterior ppz | xq takes small values (Blei et al., 2017).
While the bound in Theorem 1 has particularly simple
form, this result hinges on assumption (A2). One can show
for example that the inequality in (A2) is satisﬁed if the
posteriors ppz | x˚q are Lipschitz continuous functions of
z at z˚ (sharing one Lipschitz constant over all possible
x˚). In general however, (A2) heavily depends on both the
data distribution pX and decoder model pD. Therefore, we
provide a similar lower bound guarantee on the likelihood
of our revision x˚ under pX, which instead only relies on
weaker assumption (A3) below.
(A3) There exists L ° 0 such that for each x P X :
pDpx | zq is a L-Lipschitz function of z over BR`1p0q.

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

Here, L depends on   (through R), and we assume L • 1
without loss of generality. (A3) is guaranteed to hold in the
setting where we only consider sequences of ﬁnite length
§ T . This is because the probability output by our decoder
model, pDpx | zq, is differentiable with bounded gradi-
ents over all z P BRp0q under any sequence-to-sequence
RNN architecture which can be properly trained using gra-
dient methods. Since BR`1p0q Ä Rd is a closed interval,
pDpx | zq must be Lipschitz continuous over this set, for a
given value of x. We can simply deﬁne L to be the largest
Lipschitz constant over the |S|T possible choices of x P X
(|S| “ size of the vocabulary). In the next theorem below,
user-speciﬁed constant ↵ ° 0 is deﬁned in REVISE, and L,
 , R all depend on  .
Theorem 2. For any   ° 0, if (A1) and (A3) hold, then
with probability • 1 ´   (over x0 „ pX):

pXpx˚q • Ce´R
¨“  ¨ ↵ ¨ pXpx0q‰d`1
where constant C “ ⇡d{2
2 ` 1q ¨
 p d

pd ` 1qd
pd ` 2qd`1

Ld

Our ﬁnal result, Theorem 3, ensures that our optimization
of z˚ with respect to F is tied to the expected outcomes at
x˚ “ Dpz˚q, so that large improvements in the optimiza-
tion objective: Fpz˚q ´ FpEpx0qq imply that our revision
procedure likely produces large expected improvements in
the outcome: ErY | X “ x˚s ´ ErY | X “ x0s. For this
result, we make the following assumptions:
(A4)
PrpX P Kq • 1 ´  {2, where we deﬁne:

there exists  ° 0 such that

For any   ° 0,

K “ tx P X : x0 “ x ùñ pXpx˚q • u

(12)

as the subset of sequences whose improved versions pro-
duced by our REVISE procedure remain natural with likeli-
hood • . Note that either Theorem 1 or 2 (with the corre-
sponding assumptions) ensures that one can suitably deﬁne
 such that (A4) is satisﬁed (by considering a sufﬁciently
large ﬁnite subset of X ).
(A5) For any  ° 0, there exists ✏mse ° 0 such that
PrpX P Emseq ° 1 ´ , where we deﬁne:
Emse“ tx P X : |FpEpxqq ´ ErY |X “ xs| § ✏mseu (13)
(A6) For any   ° 0, there exists ✏inv ° 0 such that:
|Fpzq ´ FpEpDpzqqq| § ✏inv
where R is deﬁned in (11) and depends on  .
Here, ✏mse and ✏inv quantify the approximation error of our
neural networks for predicting expected outcomes and en-
suring encoding-decoding invariance with respect to F .

for all z P BRp0q Ä Rd

Standard learning theory implies both ✏mse, ✏inv will be
driven toward 0 if we use neural networks with sufﬁcient
capacity to substantially reduce Lmse and Linv over a large
training set.
Theorem 3. For any   ° 0, if conditions (A1), (A4), (A5),
and (A6) hold, then with probability • 1 ´   ´ :
 z˚ ´ ✏ § Fpz˚q ´ FpEpx0qq §  z˚ ` ✏

(14)

where

 z˚ “ ErY | X “ x˚s ´ ErY | X “ x0s
✏ “ ✏inv ` 2✏mse

Here, , ✏inv are deﬁned in terms of   as speciﬁed in (A4),
(A6), and ✏mse is deﬁned in terms of  as speciﬁed in (A5).

Experiments
All of our RNNs employ the Gated Recurrent Unit (GRU)
of Cho et al. (2014), which contains a simple gating mech-
anism to effectively learn long-range dependencies across
a sequence. Throughout, F is a simple feedforward net-
work with 1 hidden layer and tanh activations (note that the
popular ReLU activation is inappropriate for F since it has
zero gradient over half its domain). Decoding with respect
to pD is simply done entirely greedily (ie. a beam-search of
size 1) to demonstrate our approach is not reliant on search
heuristics. §S2 contains additional details for each analysis.
Simulation Study
To study our methods in a setting where all aspects of per-
formance can be quantiﬁed, we construct a natural distri-
bution pX over sequences of lengths 10-20 whose elements
stem from the vocabulary S “ tA, B, . . . , I, Ju. Each se-
quence is generated via the probabilistic grammar of Table
S1. For each sequence, the associated outcome y is sim-
ply the number of times A appears in the sequence (a com-
pletely deterministic relationship). Since A often follows C
and is almost always followed by B under pX, a procedure
to generate natural revisions cannot simply insert/substitute
A symbols at random positions.
Table 1 compares various methods for proposing revisions.
Letting  Y denote the standard deviation of outcomes
in Dn, we evaluate each proposed x˚ using a rescaled
version of the actual underlying outcome-improvement:
 Y px˚q “  ´1
Y pErY | X “ x˚s ´ ErY | X “ x0sq. Ex-
cept where sample size is explicitly listed, all models were
trained using n “ 10, 000 (sequence, outcome) pairs sam-
pled from the generative grammar. Wherever appropriate,
the different methods all make use of the same neural net-
work components with latent dimension d “ 128. Other
than ↵, all hyperparameters of each revision method de-
scribed below were chosen so that over 1000 revisions, the
Levenshtein (edit) distance dpx˚, x0q « 3.3 on average.

Model
log ↵ “ ´10000
n “ 1000
n “ 100
log ↵ “ ´1
ADAPTIVE
 inv “  pri “ 0
SEARCH

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures
 Y px˚q
0.51 ˘0.55
0.15 ˘0.44
0.02 ˘0.30
0.20 ˘0.39
0.47 ˘0.49
0.05 ˘0.68
0.45 ˘0.51

´ log pXpx˚q
29.0 ˘9.3
32.0 ˘9.4
37.0 ˘9.7
28.2 ˘7.6
28.8 ˘9.0
30.4 ˘8.4
29.0 ˘9.4

Model
log ↵ “ ´10000
log ↵ “ ´1
ADAPTIVE
 inv “  pri “ 0
SEARCH

dpx˚, x0q
3.3 ˘3.4
2.8 ˘3.4
4.2 ˘4.0
1.4 ˘2.2
3.1 ˘3.4
3.3 ˘3.5
3.2 ˘1.4

 Y px˚q
0.52 ˘0.77
0.31 ˘0.50
0.52 ˘0.72
0.22 ˘1.03
0.19 ˘0.56

 Lpx˚q
-8.8 ˘6.5
-7.6 ˘5.8
-8.7 ˘6.4
-10.2 ˘7.0
-7.7 ˘4.2

dpx˚, x0q
2.6 ˘3.3
1.7 ˘2.6
2.5 ˘3.3
3.3 ˘3.4
3.0 ˘1.2

Table 1. Results for revisions x˚ produced by different methods
in our simulation study (averaged over the same test set of 1000
starting sequences x0 „ pX, with ˘1 standard deviation shown
and the best results in bold).

All three results above the line in Table 1 are based on the
full model described in our joint training procedure, with
new sequences proposed via our REVISE algorithm (using
the setting log ↵ “ ´10000). In the latter two results, this
model was only trained on a smaller subset of the data. We
also generated revisions via this same procedure with the
more conservative choice log ↵ “ ´1. ADAPTIVE denotes
the same approach (with log ↵ “ ´10000), this time using
the adaptive decoding Dx0 introduced in §S1, which is in-
tended to slightly bias revisions toward x0. The model with
 inv “  pri “ 0 is a similar method using a deterministic
sequence-to-sequence autoencoder rather than our proba-
bilistic VAE formulation (no variational posterior approxi-
mation or invariance-enforcing) where the latent encodings
are still jointly trained to predict outcomes via F . Under
this model, a revision is proposed by starting at Epx0q in
the latent space, taking 1000 (unconstrained) gradient steps
with respect to F , and ﬁnally applying D to the resulting z.
The above methods form an ablation study of the various
components in our framework. SEARCH is a different com-
binatorial approach where we randomly generate 100 revi-
sions by performing 4 random edits in x0 (each individual
edit is randomly selected as one of: substitution, insertion,
deletion, or no change).
In this approach, we separately
learn a language-model RNN L on our training sequences
(Mikolov et al., 2010). Sharing the same GRU architec-
ture as our decoder model, L directly estimates the likeli-
hood of any given sequence under pX. Of the randomly
generated revisions, we only retain those sequences x for
which Lpxq • 1
|S| Lpx0q (in this case, those which are not
estimated to be † 10 times less likely than the original
sequence x0 under pX). Finally, we score each remain-
ing candidate (including x0) using the outcome-prediction
model FpEpxqq, and the best is chosen as x˚.
Table 1 shows that our probabilistic VAE formulation
outperforms the alternative approaches, both in terms of
outcome-improvement achieved as well as ensuring revi-

Table 2. Results for revised beer-review sentences x˚ produced
by different methods (average ˘ standard deviation reported over
the same held-out set of 1000 initial sentences x0). The third col-
umn employs the deﬁnition  Lpx˚q “ log Lpx˚q ´ log Lpx0q.

sions follow pX. For comparison, ´ log pXpx0q had an av-
erage value of 26.8 (over these 1000 starting sequences),
and changing one randomly-selected symbol in each se-
quence to A results in an average negative log-probability
of 32.8. Thus, all of our revision methods clearly account
for pX to some degree. We ﬁnd that all components used
in our REVISION procedure are useful in achieving superior
revisions. While individual standard deviations seem large,
nearly all average differences in  Y or ´ log pX values
produced by different methods are statistically signiﬁcant
considering they are over 1000 revisions.
From Supplementary Figure S1, it is clear that ↵ con-
trols how conservative the changes proposed by our RE-
VISE procedure tend to be, in terms of both ´ log pXpx˚q
and the edit distance dpx0, x˚q. The red curve in Figure
S1A suggests that our theoretical lower bounds for pXpx˚q
are overly stringent in practice (although only the average-
case is depicted in the ﬁgure). The relationship between
log pXpx0q and log pXpx˚q (see Figure S1B) is best-ﬁt by
a line of slope 1.2, indicating that the linear dependence
on pXpx0q in the Theorem 1 bound for pXpx˚q is rea-
sonably accurate. Figure S1C shows that the magnitude
of changes in the latent space (arising from z-optimization
during our REVISE procedure) only exhibits a weak corre-
lation with the edit distance between the resulting revision
and the original sequence. This implies that a ﬁxed shift in
different directions in the latent space can produce drasti-
cally different degrees of change in the sequence space. To
ensure a high-quality revision, it is thus crucial to carefully
treat the (variational) posterior landscape when performing
manipulations of Z.

Improving Sentence Positivity
Next, we apply our model to „1M reviews from BeerAd-
vocate (McAuley et al., 2012). Each beer review is parsed
into separate sentences, and each sentence is treated as an
individual sequence of words. In order to evaluate meth-
ods using an outcome that can be obtained for any pro-
posed revision, we choose y P r0, 1s as the VADER senti-
ment compound score of a given sentence (Hutto & Gilbert,

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures
dpx˚, x0q

Model
x0
log ↵ “ ´10000
ADAPTIVE
log ↵ “ ´1
 inv “  pri “ 0
SEARCH

Sentence
this smells pretty bad.
smells pretty delightful!
smells pretty delightful!
i liked this smells pretty.
pretty this smells bad!
wow this smells pretty bad.

-

 Y px˚q  Lpx˚q
-
-0.5
+2.8
-0.5
+2.8
+2.5
-2.8
-3.1
-0.2
+1.9
-4.6

-
3
3
3
3
1

Table 3. Example of a held-out beer review x0 (in bold) revised to improve the VADER sentiment. Underneath the original sentence,
we show the revision produced by each different method along with the true (rescaled) outcome improvement  Y , change in estimated
marginal likelihood  L, and edit distance dpx˚, x0q. Table S2 contains additional examples.

# Steps Decoded Sentence
x0
100
1000
5000
10000
x˚
x0
100
1000
5000
10000
x˚

where are you, henry??
where are you, henry??
where are you, royal??
where art thou now?
which cannot come, you of thee?
where art thou, keeper??
you are both the same size.
you are both the same.
you are both wretched.
you are both the king.
you are both these are very.
you are both wretched men.

Table 4. Decoding from latent Z conﬁgurations encountered at
the indicated number of (unconstrained) gradient steps from
Epx0q, for the model trained to distinguish sentences from Shake-
speare vs. contemporary authors. Shown ﬁrst and last are x0 and
the x˚ returned by our REVISION procedure (constrained with
log ↵ “ ´10000). Table S3 contains additional examples.

2014). VADER is a complex rule-based sentiment analysis
tool which jointly estimates polarity and intensity of En-
glish text, and larger VADER scores correspond to text that
humans ﬁnd more positive with high ﬁdelity.
We applied all aforementioned approaches to produce re-
visions for a held-out set of 1000 test sentences. As pX
underlying these sentences is unknown, we report estimates
thereof obtained from a RNN language-model L learned on
the sentences in Dn. Table 2 demonstrates that our VAE ap-
proach achieves the greatest outcome-improvement. More-
over, Tables 3 and S2 show that our probabilistically-
constrained VAE revision approach produces much more
coherent sentences than the other strategies.

Revising Modern Text in the Language of Shakespeare
For our ﬁnal application, we assemble a dataset of „100K
short sentences which are either from Shakespeare or a
more contemporary source (details in §S2.3). In this train-
ing data, each sentence is labeled with outcome y “ 0.9

if it was authored by Shakespeare and y “ 0.1 otherwise
(these values are chosen to avoid the ﬂat region of the sig-
moid output layer used in network F ). When applied in
this domain, our REVISE procedure thus attempts to alter
a sentence so that the author is increasingly expected to be
Shakespeare rather than a more contemporary source.
Tables 4 and S3 show revisions (of held-out sentences)
proposed by our REVISE procedure with adaptive decod-
ing (see §S1), together with sentences generated by apply-
ing the adaptive decoder at various points along an uncon-
strained gradient-ascent path in latent Z space (following
gradients of F ). Since the data lack similar versions of a
sentence written in both contemporary and Shakespearean
language, this revision task is an ambitious application of
our ideas. Without observing a continuous spectrum of out-
comes or leveraging specially-designed style transfer fea-
tures (Gatys et al., 2016), our REVISE procedure has to
alter the underlying semantics in order to nontrivially in-
crease the expected outcome of the revised sentence under
F . Nevertheless, we ﬁnd that many of the revised sentences
look realistic and resemble text written by Shakespeare.
Furthermore, these examples demonstrate how the proba-
bilistic constraint in our REVISE optimization prevents the
revision-generating latent Z conﬁgurations from straying
into regions where decodings begin to look very unnatural.

Discussion
This paper presents an efﬁcient method for optimizing dis-
crete sequences when both the objective and constraints are
stochastically estimated. Leveraging a latent-variable gen-
erative model, our procedure does not require any examples
of revisions in order to propose natural-looking sequences
with improved outcomes. These characteristics are proven
to hold with high probability in a theoretical analysis of
VAE behavior under our controlled latent-variable manip-
ulations. However, ensuring semantic similarity in text-
revisions remains difﬁcult for this approach, and might be
improved via superior VAE models or utilizing additional
similarity labels to shape the latent geometry.

Sequence to Better Sequence: Continuous Revision of Combinatorial Structures

References
Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. Varia-
tional inference: A review for statisticians. Journal of
the American Statistical Association, 2017.

Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Joze-
fowicz, R., and Bengio, S. Generating sentences from a
continuous space. Conference on Computational Natu-
ral Language Learning, 2016.

Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau,
D., Bougares, F., Schwenk, H., and Bengio, Y. Learn-
ing phrase representations using rnn encoder-decoder for
statistical machine translation. Empirical Methods on
Natural Language Processing, 2014.

Karpathy, A. The unreasonable effectiveness of recurrent
neural networks. Andrej Karpathy blog, 2015. URL
karpathy.github.io.

Kingma, D. P. and Welling, M. Auto-encoding variational
bayes. International Conference on Learning Represen-
tations, 2014.

Kiros, R., Zhu, Y., Salakhutdinov, R., Zemel, R. S., Tor-
ralba, A., Urtasun, R., and Fidler, S. Skip-thought vec-
tors. Advances in Neural Information Processing Sys-
tems, 2015.

McAuley, J., Leskovec, J., and Jurafsky, D. Learning at-
titudes and attributes from multi-aspect reviews. IEEE
International Conference on Data Mining, 2012.

Eck, D. and Schmidhuber, J. A ﬁrst look at music compo-
sition using lstm recurrent neural networks. IDSIA Tech-
nical Report, 2002.

Mikolov, T., Karaﬁat, M., Burget, L., Cernocky, J., and
Khudanpur, S. Recurrent neural network based language
model. Interspeech, 2010.

Erhan, D., Bengio, Y., Courville, A., Manzagol, P., Vin-
cent, P., and Bengio, S. Why does unsupervised pre-
training help deep learning? Journal of Machine Learn-
ing Research, 11:625–660, 2010.

Gatys, L. A., Ecker, A. S., and Bethge, M.

Image style
transfer using convolutional neural networks. Computer
Vision and Pattern Recognition, 2016.

G´omez-Bombarelli, R., Duvenaud, D., Hern´andez-Lobato,
J. M., Aguilera-Iparraguirre, J.,
, Hirzel, T., Adams,
R. P., and Aspuru-Guzik, A. Automatic chemical de-
sign using a data-driven continuous representation of
molecules. arXiv:1610.02415, 2016.

Graves, A. Generating sequences with recurrent neural net-

works. arXiv:1308.0850, 2013.

Gupta, P., Banchs, R. E., and Rosso, P. Squeezing bot-
tlenecks: Exploring the limits of autoencoder semantic
representation capabilities. Neurocomputing, 175:1001–
1008, 2016.

Higgins, I., Matthey, L., Glorot, X., Pal, A., Uria, B.,
Blundell, C., Mohamed, S., and Lerchner, A. Early vi-
sual concept learning with unsupervised deep learning.
arXiv:1606.05579, 2016.

Hoffman, M. D. and Johnson, M. J. Elbo surgery: yet
another way to carve up the variational evidence lower
bound. NIPS Workshop on Advances in Approximate
Bayesian Inference, 2016.

Hutto, C.J. and Gilbert, E. Vader: A parsimonious rule-
based model for sentiment analysis of social media text.
Eighth International Conference on Weblogs and Social
Media, 2014.

Mueller, J. and Thyagarajan, A. Siamese recurrent archi-
tectures for learning sentence similarity. Proc. AAAI
Conference on Artiﬁcial Intelligence, 2016.

Mueller, J., Reshef, D. N., Du, G., and Jaakkola, T. Learn-
ing optimal interventions. Artiﬁcial Intelligence and
Statistics, 2017.

Nguyen, A., Yosinski, J., and Clune, J. Deep neural net-
works are easily fooled: High conﬁdence predictions for
unrecognizable images. Computer Vision and Pattern
Recognition, 2015.

Nguyen, A., Dosovitskiy, A., Yosinski, J., Brox, T., and
Clune, J. Synthesizing the preferred inputs for neurons in
neural networks via deep generator networks. Advances
in Neural Information Processing Systems, 2016.

Simonyan, K., Vedaldi, A., and Zisserman, A. Deep inside
convolutional networks: Visualising image classiﬁcation
models and saliency maps. ICLR Workshop Proceedings,
2014.

Sutskever, I., Vinyals, O., and Le, Q.V. Sequence to se-
quence learning with neural networks. Advances in Neu-
ral Information Processing Systems, 2014.

Wiseman, S. and Rush, A. M. Sequence-to-sequence learn-
ing as beam-search optimization. Empirical Methods in
Natural Language Processing, 2016.

Zaefferer, M., Stork, J., Friese, M., Fischbach, A., Naujoks,
B., and Bartz-Beielstein, T. Efﬁcient global optimization
for combinatorial problems. Genetic and Evolutionary
Computation Conference, 2014.

